from bs4 import BeautifulSoup
import requests

url= 'https://fpl.team/predictions/?sort=pts&position=&club=&ownership=100&start=10&end=38'
page= requests.get(url)
soup1= BeautifulSoup(page.content, 'html.parser')
soup2= BeautifulSoup(soup1.prettify(),'html.parser')

titles=soup2.find_all(class_='player-title fw-bold')
cleantitles= [title.text.strip() for title in titles]
xps=soup2.find_all(class_='player-value')
cleanxps= [title.text.strip() for title in xps]
positions=soup2.find_all(class_='player-subtitle')
cleanpositions= [title.text.strip() for title in positions]

for item in cleantitles:
    parts = item.split()
    name = ' '.join(parts[:-1])
    number = (parts[-1])

for item in cleanpositions:
    parts = item.split('/')
    pos = parts[0]
    team = parts[1]
    owns = parts[2] 

names = []  # Initialize an empty list for names
numbers = []  # Initialize an empty list for numbers(prices)
for item in cleantitles:
    parts = item.split()
    name = ' '.join(parts[:-1])
    number = (parts[-1])
    names.append(name)  # Append the name to the names list
    numbers.append(number)  # Append the number to the numbers list

pos = []    # Initialize an empty list for positions
team = []   # Initialize an empty list for team
owns = []   # Initialize an empty list for ownership
for item in cleanpositions:
    parts = item.split('/')
    pos.append(parts[0])      # Append the position to the 'pos' list
    team.append(parts[1])     # Append the team to the 'team' list
    owns.append(parts[2])     # Append the ownership to the 'owns' list

info = list(zip(names, cleanxps, numbers, owns, team, pos))

import pandas as pd
df = pd.DataFrame(info, columns=["Name", "Xp","Price","Owns","Team","Pos"])
df

#converting what we got to csv files in our pc, after the coma we used index=false to remove the useless index num
df.to_csv(r'/Users/aihamibdah/Desktop/Path For Python/FPL_DATA_UPDATED.csv', index= False)

